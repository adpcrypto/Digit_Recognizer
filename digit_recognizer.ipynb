{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-05T15:27:53.585324Z",
     "iopub.status.busy": "2021-09-05T15:27:53.584914Z",
     "iopub.status.idle": "2021-09-05T15:27:53.60033Z",
     "shell.execute_reply": "2021-09-05T15:27:53.599406Z",
     "shell.execute_reply.started": "2021-09-05T15:27:53.585241Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:27:53.602026Z",
     "iopub.status.busy": "2021-09-05T15:27:53.601748Z",
     "iopub.status.idle": "2021-09-05T15:27:59.872066Z",
     "shell.execute_reply": "2021-09-05T15:27:59.871242Z",
     "shell.execute_reply.started": "2021-09-05T15:27:53.602001Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 as cv\n",
    "\n",
    "from keras.layers import Conv2D, Input, LeakyReLU, Dense, Activation, Flatten, Dropout, MaxPool2D\n",
    "from keras import models\n",
    "from keras.optimizers import Adam,RMSprop \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:27:59.873914Z",
     "iopub.status.busy": "2021-09-05T15:27:59.873468Z",
     "iopub.status.idle": "2021-09-05T15:28:03.716067Z",
     "shell.execute_reply": "2021-09-05T15:28:03.715315Z",
     "shell.execute_reply.started": "2021-09-05T15:27:59.873886Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1) # seed\n",
    "df_train = pd.read_csv(\"../input/digit-recognizer/train.csv\") # Loading Dataset\n",
    "df_train = df_train.iloc[np.random.permutation(len(df_train))] # Random permutaion for dataset (seed is used to resample the same permutation every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:03.718117Z",
     "iopub.status.busy": "2021-09-05T15:28:03.717529Z",
     "iopub.status.idle": "2021-09-05T15:28:03.749286Z",
     "shell.execute_reply": "2021-09-05T15:28:03.748338Z",
     "shell.execute_reply.started": "2021-09-05T15:28:03.718075Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:03.751131Z",
     "iopub.status.busy": "2021-09-05T15:28:03.750595Z",
     "iopub.status.idle": "2021-09-05T15:28:03.757634Z",
     "shell.execute_reply": "2021-09-05T15:28:03.756622Z",
     "shell.execute_reply.started": "2021-09-05T15:28:03.751094Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:03.759438Z",
     "iopub.status.busy": "2021-09-05T15:28:03.759055Z",
     "iopub.status.idle": "2021-09-05T15:28:03.769088Z",
     "shell.execute_reply": "2021-09-05T15:28:03.768266Z",
     "shell.execute_reply.started": "2021-09-05T15:28:03.759409Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = df_train.shape[0] # Training set size\n",
    "validation_size = int(df_train.shape[0]*0.1) # Validation set size \n",
    "\n",
    "# train_x and train_y\n",
    "train_x = np.asarray(df_train.iloc[:sample_size-validation_size,1:]).reshape([sample_size-validation_size,28,28,1]) # taking all columns expect column 0\n",
    "train_y = np.asarray(df_train.iloc[:sample_size-validation_size,0]).reshape([sample_size-validation_size,1]) # taking column 0\n",
    "\n",
    "# val_x and val_y\n",
    "val_x = np.asarray(df_train.iloc[sample_size-validation_size:,1:]).reshape([validation_size,28,28,1])\n",
    "val_y = np.asarray(df_train.iloc[sample_size-validation_size:,0]).reshape([validation_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:03.772274Z",
     "iopub.status.busy": "2021-09-05T15:28:03.771975Z",
     "iopub.status.idle": "2021-09-05T15:28:03.784239Z",
     "shell.execute_reply": "2021-09-05T15:28:03.783292Z",
     "shell.execute_reply.started": "2021-09-05T15:28:03.772249Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x.shape,train_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:03.786883Z",
     "iopub.status.busy": "2021-09-05T15:28:03.786569Z",
     "iopub.status.idle": "2021-09-05T15:28:05.827781Z",
     "shell.execute_reply": "2021-09-05T15:28:05.826897Z",
     "shell.execute_reply.started": "2021-09-05T15:28:03.786857Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "test_x = np.asarray(df_test.iloc[:,:]).reshape([-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:05.829645Z",
     "iopub.status.busy": "2021-09-05T15:28:05.829379Z",
     "iopub.status.idle": "2021-09-05T15:28:06.046727Z",
     "shell.execute_reply": "2021-09-05T15:28:06.045827Z",
     "shell.execute_reply.started": "2021-09-05T15:28:05.829619Z"
    }
   },
   "outputs": [],
   "source": [
    "# convirting pixel values in range [0,1]\n",
    "train_x = train_x/255\n",
    "val_x = val_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:06.048273Z",
     "iopub.status.busy": "2021-09-05T15:28:06.048009Z",
     "iopub.status.idle": "2021-09-05T15:28:06.360086Z",
     "shell.execute_reply": "2021-09-05T15:28:06.359333Z",
     "shell.execute_reply.started": "2021-09-05T15:28:06.048248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cheacking frequency of digits in training and validation set\n",
    "counts = df_train.iloc[:sample_size-validation_size,:].groupby('label')['label'].count()\n",
    "# df_train.head(2)\n",
    "# counts\n",
    "f = plt.figure(figsize=(10,6))\n",
    "f.add_subplot(111)\n",
    "\n",
    "plt.bar(counts.index,counts.values,width = 0.8,color=\"orange\")\n",
    "for i in counts.index:\n",
    "    plt.text(i,counts.values[i]+50,str(counts.values[i]),horizontalalignment='center',fontsize=14)\n",
    "\n",
    "plt.tick_params(labelsize = 14)\n",
    "plt.xticks(counts.index)\n",
    "plt.xlabel(\"Digits\",fontsize=16)\n",
    "plt.ylabel(\"Frequency\",fontsize=16)\n",
    "plt.title(\"Frequency Graph training set\",fontsize=20)\n",
    "plt.savefig('digit_frequency_train.png')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:06.361638Z",
     "iopub.status.busy": "2021-09-05T15:28:06.361194Z",
     "iopub.status.idle": "2021-09-05T15:28:06.61859Z",
     "shell.execute_reply": "2021-09-05T15:28:06.61773Z",
     "shell.execute_reply.started": "2021-09-05T15:28:06.361608Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.iloc[sample_size-validation_index:,1:]\n",
    "# Cheacking frequency of digits in training and validation set\n",
    "counts = df_train.iloc[sample_size-validation_size:,:].groupby('label')['label'].count()\n",
    "# df_train.head(2)\n",
    "# counts\n",
    "f = plt.figure(figsize=(10,6))\n",
    "f.add_subplot(111)\n",
    "\n",
    "plt.bar(counts.index,counts.values,width = 0.8,color=\"orange\")\n",
    "for i in counts.index:\n",
    "    plt.text(i,counts.values[i]+5,str(counts.values[i]),horizontalalignment='center',fontsize=14)\n",
    "\n",
    "plt.tick_params(labelsize = 14)\n",
    "plt.xticks(counts.index)\n",
    "plt.xlabel(\"Digits\",fontsize=16)\n",
    "plt.ylabel(\"Frequency\",fontsize=16)\n",
    "plt.title(\"Frequency Graph Validation set\",fontsize=20)\n",
    "plt.savefig('digit_frequency_val.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:06.620026Z",
     "iopub.status.busy": "2021-09-05T15:28:06.619742Z",
     "iopub.status.idle": "2021-09-05T15:28:08.171385Z",
     "shell.execute_reply": "2021-09-05T15:28:08.170223Z",
     "shell.execute_reply.started": "2021-09-05T15:28:06.619993Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 5 # defining no. of rows in figure\n",
    "cols = 6 # defining no. of colums in figure\n",
    "\n",
    "f = plt.figure(figsize=(2*cols,2*rows)) # defining a figure \n",
    "\n",
    "for i in range(rows*cols): \n",
    "    f.add_subplot(rows,cols,i+1) # adding sub plot to figure on each iteration\n",
    "    plt.imshow(train_x[i].reshape([28,28]),cmap=\"Blues\") \n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(train_y[i]), y=-0.15,color=\"green\")\n",
    "plt.savefig(\"digits.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:08.174691Z",
     "iopub.status.busy": "2021-09-05T15:28:08.174394Z",
     "iopub.status.idle": "2021-09-05T15:28:08.214471Z",
     "shell.execute_reply": "2021-09-05T15:28:08.213715Z",
     "shell.execute_reply.started": "2021-09-05T15:28:08.174661Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:08.216855Z",
     "iopub.status.busy": "2021-09-05T15:28:08.216527Z",
     "iopub.status.idle": "2021-09-05T15:28:08.366809Z",
     "shell.execute_reply": "2021-09-05T15:28:08.366056Z",
     "shell.execute_reply.started": "2021-09-05T15:28:08.216826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Block 1\n",
    "model.add(Conv2D(32,3, padding  =\"same\",input_shape=(28,28,1)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Conv2D(32,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:28:08.36819Z",
     "iopub.status.busy": "2021-09-05T15:28:08.367832Z",
     "iopub.status.idle": "2021-09-05T15:28:08.389816Z",
     "shell.execute_reply": "2021-09-05T15:28:08.388427Z",
     "shell.execute_reply.started": "2021-09-05T15:28:08.368157Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "model.compile(Adam(lr=initial_lr), loss=loss ,metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-05T15:37:57.494968Z",
     "iopub.status.busy": "2021-09-05T15:37:57.494604Z",
     "iopub.status.idle": "2021-09-05T15:37:57.498907Z",
     "shell.execute_reply": "2021-09-05T15:37:57.497871Z",
     "shell.execute_reply.started": "2021-09-05T15:37:57.494938Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "history_1 = model.fit(train_x,train_y,batch_size=batch_size,epochs=epochs,validation_data=[val_x,val_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.463531Z",
     "iopub.status.idle": "2021-09-05T15:29:24.464053Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "with open('history_1.hs', 'wb') as history:\n",
    "    pickle.dump(history_1,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.465307Z",
     "iopub.status.idle": "2021-09-05T15:29:24.465991Z"
    }
   },
   "outputs": [],
   "source": [
    "f= plt.figure(figsize=(20,7))\n",
    "\n",
    "#Adding Subplot 1 (For Accuracy)\n",
    "f.add_subplot(121)\n",
    "\n",
    "plt.plot(history_1.epoch,history_1.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set\n",
    "plt.plot(history_1.epoch,history_1.history['val_accuracy'],label = \"val_accuracy\") # Accuracy curve for validation set\n",
    "\n",
    "plt.title(\"Accuracy Curve\",fontsize=18)\n",
    "plt.xlabel(\"Epochs\",fontsize=15)\n",
    "plt.ylabel(\"Accuracy\",fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "#Adding Subplot 1 (For Loss)\n",
    "f.add_subplot(122)\n",
    "\n",
    "plt.plot(history_1.epoch,history_1.history['loss'],label=\"loss\") # Loss curve for training set\n",
    "plt.plot(history_1.epoch,history_1.history['val_loss'],label=\"val_loss\") # Loss curve for validation set\n",
    "\n",
    "plt.title(\"Loss Curve\",fontsize=18)\n",
    "plt.xlabel(\"Epochs\",fontsize=15)\n",
    "plt.ylabel(\"Loss\",fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.467537Z",
     "iopub.status.idle": "2021-09-05T15:29:24.468211Z"
    }
   },
   "outputs": [],
   "source": [
    "val_p = np.argmax(model.predict(val_x),axis =1)\n",
    "\n",
    "error = 0\n",
    "confusion_matrix = np.zeros([10,10])\n",
    "for i in range(val_x.shape[0]):\n",
    "    confusion_matrix[val_y[i],val_p[i]] += 1\n",
    "    if val_y[i]!=val_p[i]:\n",
    "        error +=1\n",
    "        \n",
    "print(\"Confusion Matrix: \\n\\n\" ,confusion_matrix)\n",
    "print(\"\\nErrors in validation set: \" ,error)\n",
    "print(\"\\nError Persentage : \" ,(error*100)/val_p.shape[0])\n",
    "print(\"\\nAccuracy : \" ,100-(error*100)/val_p.shape[0])\n",
    "print(\"\\nValidation set Shape :\",val_p.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.469724Z",
     "iopub.status.idle": "2021-09-05T15:29:24.47041Z"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,8.5))\n",
    "f.add_subplot(111)\n",
    "\n",
    "plt.imshow(np.log2(confusion_matrix+1),cmap=\"Reds\")\n",
    "plt.colorbar()\n",
    "plt.tick_params(size=5,color=\"white\")\n",
    "plt.xticks(np.arange(0,10),np.arange(0,10))\n",
    "plt.yticks(np.arange(0,10),np.arange(0,10))\n",
    "\n",
    "threshold = confusion_matrix.max()/2 \n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.text(j,i,int(confusion_matrix[i,j]),horizontalalignment=\"center\",color=\"white\" if confusion_matrix[i, j] > threshold else \"black\")\n",
    "        \n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"Confusion_matrix1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.471697Z",
     "iopub.status.idle": "2021-09-05T15:29:24.472362Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.473713Z",
     "iopub.status.idle": "2021-09-05T15:29:24.474425Z"
    }
   },
   "outputs": [],
   "source": [
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',patience=2,verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.475703Z",
     "iopub.status.idle": "2021-09-05T15:29:24.4764Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history_2 = model.fit_generator(datagen.flow(train_x,train_y, batch_size=batch_size),steps_per_epoch=int(train_x.shape[0]/batch_size)+1,epochs=epochs,validation_data=[val_x,val_y],callbacks=[lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.477747Z",
     "iopub.status.idle": "2021-09-05T15:29:24.478457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diffining Figure\n",
    "f = plt.figure(figsize=(20,7))\n",
    "f.add_subplot(121)\n",
    "\n",
    "#Adding Subplot 1 (For Accuracy)\n",
    "plt.plot(history_1.epoch+list(np.asarray(history_2.epoch) + len(history_1.epoch)),history_1.history['accuracy']+history_2.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set\n",
    "plt.plot(history_1.epoch+list(np.asarray(history_2.epoch) + len(history_1.epoch)),history_1.history['val_accuracy']+history_2.history['val_accuracy'],label = \"val_accuracy\") # Accuracy curve for validation set\n",
    "\n",
    "plt.title(\"Accuracy Curve\",fontsize=18)\n",
    "plt.xlabel(\"Epochs\",fontsize=15)\n",
    "plt.ylabel(\"Accuracy\",fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#Adding Subplot 1 (For Loss)\n",
    "f.add_subplot(122)\n",
    "\n",
    "plt.plot(history_1.epoch+list(np.asarray(history_2.epoch) + len(history_1.epoch)),history_1.history['loss']+history_2.history['loss'],label=\"loss\") # Loss curve for training set\n",
    "plt.plot(history_1.epoch+list(np.asarray(history_2.epoch) + len(history_1.epoch)),history_1.history['val_loss']+history_2.history['val_loss'],label=\"val_loss\") # Loss curve for validation set\n",
    "\n",
    "plt.title(\"Loss Curve\",fontsize=18)\n",
    "plt.xlabel(\"Epochs\",fontsize=15)\n",
    "plt.ylabel(\"Loss\",fontsize=15)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.479906Z",
     "iopub.status.idle": "2021-09-05T15:29:24.480547Z"
    }
   },
   "outputs": [],
   "source": [
    "val_p = np.argmax(model.predict(val_x),axis =1)\n",
    "\n",
    "error = 0\n",
    "confusion_matrix = np.zeros([10,10])\n",
    "for i in range(val_x.shape[0]):\n",
    "    confusion_matrix[val_y[i],val_p[i]] += 1\n",
    "    if val_y[i]!=val_p[i]:\n",
    "        error +=1\n",
    "        \n",
    "confusion_matrix,error,(error*100)/val_p.shape[0],100-(error*100)/val_p.shape[0],val_p.shape[0]\n",
    "\n",
    "print(\"Confusion Matrix: \\n\\n\" ,confusion_matrix)\n",
    "print(\"\\nErrors in validation set: \" ,error)\n",
    "print(\"\\nError Persentage : \" ,(error*100)/val_p.shape[0])\n",
    "print(\"\\nAccuracy : \" ,100-(error*100)/val_p.shape[0])\n",
    "print(\"\\nValidation set Shape :\",val_p.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.481866Z",
     "iopub.status.idle": "2021-09-05T15:29:24.482295Z"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,8.5))\n",
    "f.add_subplot(111)\n",
    "\n",
    "plt.imshow(np.log2(confusion_matrix+1),cmap=\"Reds\")\n",
    "plt.colorbar()\n",
    "plt.tick_params(size=5,color=\"white\")\n",
    "plt.xticks(np.arange(0,10),np.arange(0,10))\n",
    "plt.yticks(np.arange(0,10),np.arange(0,10))\n",
    "\n",
    "threshold = confusion_matrix.max()/2 \n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.text(j,i,int(confusion_matrix[i,j]),horizontalalignment=\"center\",color=\"white\" if confusion_matrix[i, j] > threshold else \"black\")\n",
    "        \n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"Confusion_matrix2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.483066Z",
     "iopub.status.idle": "2021-09-05T15:29:24.483471Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 4\n",
    "cols = 9\n",
    "\n",
    "f = plt.figure(figsize=(2*cols,2*rows))\n",
    "sub_plot = 1\n",
    "for i in range(val_x.shape[0]):\n",
    "    if val_y[i]!=val_p[i]:\n",
    "        f.add_subplot(rows,cols,sub_plot) \n",
    "        sub_plot+=1\n",
    "        plt.imshow(val_x[i].reshape([28,28]),cmap=\"Blues\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"T: \"+str(val_y[i])+\" P:\"+str(val_p[i]), y=-0.15,color=\"Red\")\n",
    "plt.savefig(\"error_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.484303Z",
     "iopub.status.idle": "2021-09-05T15:29:24.484797Z"
    }
   },
   "outputs": [],
   "source": [
    "test_y = np.argmax(model.predict(test_x),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.485544Z",
     "iopub.status.idle": "2021-09-05T15:29:24.486088Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 10\n",
    "\n",
    "f = plt.figure(figsize=(2*cols,2*rows))\n",
    "\n",
    "for i in range(rows*cols):\n",
    "    f.add_subplot(rows,cols,i+1)\n",
    "    plt.imshow(test_x[i].reshape([28,28]),cmap=\"Blues\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(test_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.486973Z",
     "iopub.status.idle": "2021-09-05T15:29:24.487372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extracts the outputs of all layers except Flatten and Dense layers\n",
    "output_layers = [layer.output for layer in model.layers[:-4]]\n",
    "# Creates a model that will return these outputs, given the model input (This is multi output model)\n",
    "activation_model = models.Model(inputs=model.input, outputs=output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.488098Z",
     "iopub.status.idle": "2021-09-05T15:29:24.488529Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicting the output of each layers\n",
    "activations_2  = activation_model.predict(val_x[2].reshape([1,28,28,1]))\n",
    "activations_6  = activation_model.predict(val_x[7].reshape([1,28,28,1]))\n",
    "first_activation_layer  = activations_2[0]\n",
    "first_activation_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.489553Z",
     "iopub.status.idle": "2021-09-05T15:29:24.489967Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 4\n",
    "cols = 2\n",
    "\n",
    "f = plt.figure(figsize=(2*cols,2*rows))\n",
    "\n",
    "for i in range(4):\n",
    "    f.add_subplot(rows,cols,2*i+1)\n",
    "    plt.imshow(activations_2[0][0,:,:,i].reshape([28,28]),cmap=\"Blues\")\n",
    "    plt.axis(\"off\") \n",
    "\n",
    "    f.add_subplot(rows,cols,2*i+2)\n",
    "    plt.imshow(activations_6[0][0,:,:,i].reshape([28,28]),cmap=\"Blues\")\n",
    "    plt.savefig(\"layer_output_comparision\"+str(i)+\".png\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.49088Z",
     "iopub.status.idle": "2021-09-05T15:29:24.491322Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_layer(layer,i,layer_name = None):\n",
    "    rows = layer.shape[-1]/16\n",
    "    cols = 16\n",
    "\n",
    "    f = plt.figure(figsize=(1*cols,1*rows))\n",
    "    # plt.imshow(first_activation_layer[0,:,:,:].reshape([14*4,14*16]),cmap=\"Blues\")\n",
    "    for i in range(layer.shape[-1]):\n",
    "        f.add_subplot(rows,cols,i+1)\n",
    "        plt.imshow(layer[0,:,:,i].reshape([layer.shape[2],layer.shape[2]]),cmap=\"Blues\")\n",
    "        plt.axis(\"off\")\n",
    "    f.suptitle(layer_name,fontsize=14)\n",
    "    plt.savefig(\"intermidiate_layers\"+str(i)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.492242Z",
     "iopub.status.idle": "2021-09-05T15:29:24.492652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualising each layers\n",
    "for i,layer in enumerate(activation_model.predict(val_x[6].reshape([1,28,28,1]))):\n",
    "    plot_layer(layer,i,output_layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-05T15:29:24.493694Z",
     "iopub.status.idle": "2021-09-05T15:29:24.49417Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame([df_test.index+1,test_y],[\"ImageId\",\"Label\"]).transpose()\n",
    "df_submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
